{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d8c2d6-2023-42af-bf77-2d66071e737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca2eed0-2f6a-4ced-9a0f-ddcd3bec3e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r\"C:\\Users\\Garv Khurana\\OneDrive\\Desktop\\datasets\\IMDB Dataset.csv\",)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58929ab0-7f52-4160-b488-3e77bbfae699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df[\"sentiment\"]=le.fit_transform(df[\"sentiment\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c4e405-326d-4bda-9e52-7eef28cb1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=list(df[\"review\"])\n",
    "y=list(df[\"sentiment\"])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=50,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240a767f-34e5-450f-a90c-97b5d5e979ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tokenizer(x_train,padding=True,truncation=True,return_tensors=\"tf\")\n",
    "x_test=tokenizer(x_test,padding=True,truncation=True,return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "713e49c4-197b-413b-82a7-6bd2d9ecb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset=tensorflow.data.Dataset.from_tensor_slices((dict(x_train),y_train)).batch(16)\n",
    "test_dataset=tensorflow.data.Dataset.from_tensor_slices((dict(x_test),y_test)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7676daf3-a7f7-4d09-98d4-1f8319e3b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "array([  101,  2023,  3185,  2001,  6659,  1012,  1012,  1012,  2129,\n",
       "        2064,  8307,  2130,  2228,  2008,  2023,  3185,  2001,  2066,\n",
       "        1996,  3924,  2067,  1999,  1996,  1000,  2204,  2214,  2420,\n",
       "        1000,  2043,  5199, 19438, 18617,  2001,  2025,  2130,  1999,\n",
       "        2009,  1012,  1998,  2000,  2191,  2477,  4788,  1010,  2027,\n",
       "        2109, 15281,  2013,  2214, 16588,  2099,  5691,  1012,  2008,\n",
       "        2015,  2074,  6659,  1012,  2053, 16588,  2099,  3185,  2003,\n",
       "        3143,  2302,  5199, 19438, 18617,  1012,  1045,  2293,  2440,\n",
       "        5302,  2239,  3152,  1010,  1998,  1045,  2031,  2042,  3666,\n",
       "        2068,  2144,  1045,  2001,  1018,  2086,  2214,  1012,  1045,\n",
       "        2031,  2042,  2083,  2673,  2027,  2031,  2589,  1998,  2023,\n",
       "        3185,  2471,  2081,  2033,  4558,  2009,  1012,  2085,  1045,\n",
       "        2288,  1037,  3232,  1997,  3210,  2000,  6039,  2061,  1045,\n",
       "        2097,  2562,  2183,  1012,  2037,  2126,  1997,  8119,  2047,\n",
       "       16588,  2869,  2003,  3294,  5236,  2004,  2092,  2004,  2126,\n",
       "        2000,  4604,  2990,  2067,  1999,  2051,  1012,  2054,  3047,\n",
       "        2000,  1996, 22975,  2140,  4574,  1012,  1998,  2633,   999,\n",
       "        2054,  3047,  1999,  1996,  2203,  1997, 16588,  2869,  1019,\n",
       "        2073, 27022,  2758,  1998,  1045, 14686,  1000,  2990,  2038,\n",
       "        2445,  2033,  2242,  2569,  1000,  1998,  2014,  1998,  2070,\n",
       "        2060,  5041,  3504,  2012,  2014,  4308,  1012,  1045,  2123,\n",
       "        1005,  1056,  2113,  1012,  1012,  1012,  2672,  1037,  3336,\n",
       "        2003,  1999,  2045,  1012,  2045,  2020,  2061,  2116,  2060,\n",
       "        3182,  1997,  2183,  2000,  1010,  2021,  2440,  5302,  2239,\n",
       "        1055,  1005,  1040,  1996,  2793,   102,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f0c5921-4fb3-4af4-aff4-6e736a32fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tensorflow.keras.losses.SparseCategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer,loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2742dc6-76d8-4e03-96cb-1337b7f58d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb0bcec-7d67-45db-8e5b-c32ba6ca2281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f46449c-25b0-4c53-8e18-8d98715676d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1873/1875 [============================>.] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1819\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1817\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `train_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1821\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty logs). This could be due to issues in input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline that resulted in an empty dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1823\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1827\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1828\u001b[0m     )\n\u001b[0;32m   1829\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n\u001b[0;32m   1830\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_get_metrics_result(logs)\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "model.fit(training_dataset,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb20a17-d862-4642-ae35-21f7b633bf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
